{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-espncricinfo in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (0.5.8)\n",
      "Requirement already satisfied: bs4 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from python-espncricinfo) (0.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from python-espncricinfo) (2.24.0)\n",
      "Requirement already satisfied: dateparser in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from python-espncricinfo) (1.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from bs4->python-espncricinfo) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from dateparser->python-espncricinfo) (2.8.1)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from dateparser->python-espncricinfo) (1.5.1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from dateparser->python-espncricinfo) (2020.6.8)\n",
      "Requirement already satisfied: pytz in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from dateparser->python-espncricinfo) (2020.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from requests->python-espncricinfo) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from requests->python-espncricinfo) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from requests->python-espncricinfo) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from requests->python-espncricinfo) (2.10)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->python-espncricinfo) (2.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from python-dateutil->dateparser->python-espncricinfo) (1.12.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from bs4) (4.8.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\hanish.chebrole\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-espncricinfo\n",
    "!pip3 install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from espncricinfo.exceptions import MatchNotFoundError, NoScorecardError\n",
    "import dateparser\n",
    "from espncricinfo.exceptions import PlayerNotFoundError\n",
    "from datetime import datetime,date\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Match(object):\n",
    "\n",
    "    def __init__(self, match_id):\n",
    "        self.match_id = match_id\n",
    "        self.match_url = \"https://www.espncricinfo.com/matches/engine/match/{0}.html\".format(str(match_id))\n",
    "        self.json_url = \"https://www.espncricinfo.com/matches/engine/match/{0}.json\".format(str(match_id))\n",
    "        self.json = self.get_json()\n",
    "        self.html = self.get_html()\n",
    "        if self.json:\n",
    "           \n",
    "            self.series = self._series()\n",
    "            \n",
    "            self.team_1 = self._team_1()\n",
    "\n",
    "            self.team_2 = self._team_2()\n",
    "            \n",
    "            self.team_1_players = self._team_1_players()\n",
    "            \n",
    "            self.team_2_players = self._team_2_players()\n",
    "            \n",
    "            self.date = self._date()\n",
    "            \n",
    "\n",
    "    def __str__(self):\n",
    "        return self.description\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'{self.__class__.__name__}('f'{self.match_id!r})')\n",
    "\n",
    "    def get_json(self):\n",
    "        r = requests.get(self.json_url)\n",
    "        if r.status_code == 404:\n",
    "            raise MatchNotFoundError\n",
    "        elif 'Scorecard not yet available' in r.text:\n",
    "            raise NoScorecardError\n",
    "        else:\n",
    "            return r.json()\n",
    "        \n",
    "    def match_json(self):\n",
    "        return self.json['match']\n",
    "\n",
    "    def get_html(self):\n",
    "        r = requests.get(self.match_url)\n",
    "        if r.status_code == 404:\n",
    "            raise MatchNotFoundError\n",
    "        else:\n",
    "            return bs(r.text, 'html.parser')\n",
    "\n",
    "   \n",
    "    def _series(self):\n",
    "        return self.json['series']\n",
    "\n",
    "    def _team_1(self):\n",
    "        return self.json['team'][0]\n",
    "\n",
    "    def _team_2(self):\n",
    "        return self.json['team'][1]\n",
    "\n",
    "    def _team_1_players(self):\n",
    "        return self._team_1().get('player', [])\n",
    "    \n",
    "    def _team_2_players(self):\n",
    "        return self._team_2().get('player', [])\n",
    "    \n",
    "    def _date(self):        \n",
    "        return self.match_json()['start_date_raw']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorecard(index,table,m):\n",
    "    tableValues = []\n",
    "\n",
    "    for x in table[index].find_all('tr')[1:]:\n",
    "        td_tags = x.find_all('td')\n",
    "        td_val = [y.text for y in td_tags]\n",
    "        tableValues.append(td_val)\n",
    "\n",
    "    row_headers = []\n",
    "\n",
    "    for x in table[index].find_all('tr'):\n",
    "        for y in x.find_all('th'):\n",
    "            row_headers.append(y.text)\n",
    "\n",
    "\n",
    "    df=pd.DataFrame(tableValues,columns=row_headers)\n",
    "    df.columns.values[1] ='CB'\n",
    "    df=df.drop(\"\\xa0\",axis=1,errors='ignore')\n",
    "\n",
    "    if df['BATTING'].str.contains(\"Did not bat\").any():    \n",
    "\n",
    "        df_clean=df.set_index('BATTING').dropna(axis=0,how='all')\n",
    "        df_clean=df_clean.iloc[0:df_clean.index.get_indexer(['Extras'])[0]].reset_index().rename(columns={'\\xa0':'CB'})\n",
    "        dnb=df['BATTING'][df['BATTING'].str.contains(\"Did not bat\")==True].str.replace(\":\",\",\").str.split(\",\",expand=True).drop([0],axis=1).T\n",
    "        dnb.columns=['BATTING']\n",
    "        df_dnb=pd.concat([df_clean,dnb],axis=0).reset_index().drop(\"index\",axis=1)\n",
    "        df_dnb['CB']=df_dnb['CB'].fillna('dnb')\n",
    "        df_dnb=df_dnb.fillna(0)\n",
    "        df=df_dnb\n",
    "    else:\n",
    "        df=pd.DataFrame(tableValues,columns=row_headers).set_index('BATTING').dropna(axis=0,how='all')\n",
    "        df=df.iloc[0:df.index.get_indexer(['Extras'])[0]].reset_index().rename(columns={'\\xa0':'CB'})\n",
    "\n",
    "    df['BATTING']=df['BATTING'].replace(regex=True,to_replace=r'[^A-Z a-z ().\\-]', value=r'')\n",
    "\n",
    "    if len(df['CB'].replace(regex=True,to_replace=[\"c \",r'[^A-Z a-z (/ .\\-]'], value=r'').str.replace(\"(\",\"-\").str.split(\" b \",expand=True).columns)>1:\n",
    "\n",
    "        df[['caught','bowled']]=df['CB'].replace(regex=True,to_replace=[\"c \",r'[^A-Z a-z (/ .\\-]'], value=r'').str.replace(\"(\",\"-\").str.split(\" b \",expand=True)\n",
    "\n",
    "        #Split data for run_out\n",
    "\n",
    "        df1=df.caught.str.split(\"run out -\",expand=True)\n",
    "\n",
    "        if len(df1.columns) > 1:\n",
    "\n",
    "            df1=df1[1].str.split(\"/\",expand=True)\n",
    "\n",
    "            if len(df1.columns)==2:\n",
    "                df[['run_out_1','run_out_2']]=df1\n",
    "                run_out_id=list(df[\"caught\"].apply(lambda x: x if \"run out -\" in x else None).dropna().index)\n",
    "                df[\"caught\"][run_out_id]=df[\"caught\"][run_out_id].replace(df[\"caught\"][run_out_id],'None')\n",
    "            elif len(df1.columns)==1:\n",
    "                df['run_out_dh']=df1\n",
    "                run_out_id=list(df[\"caught\"].apply(lambda x: x if \"run out -\" in x else None).dropna().index)\n",
    "                df[\"caught\"][run_out_id]=df[\"caught\"][run_out_id].replace(df[\"caught\"][run_out_id],'None')\n",
    "            else:\n",
    "                None\n",
    "        else:\n",
    "            None\n",
    "\n",
    "\n",
    "\n",
    "        ## Stumped\n",
    "\n",
    "        if len(df.caught.str.split(\"st \",expand=True).columns)>1:\n",
    "            df['stumped_out_by']=df.caught.str.split(\"st \",expand=True)[1]\n",
    "            st_id=list(df[\"caught\"].apply(lambda x: x if \"st \" in x else None).dropna().index)\n",
    "            df[\"caught\"][st_id]=df[\"caught\"][st_id].replace(df[\"caught\"][st_id],'None')\n",
    "        else:\n",
    "            None\n",
    "\n",
    "\n",
    "        ## Hit - Wicket\n",
    "\n",
    "        if len(df.caught.str.split(\"hit wicket \",expand=True).columns)>1:\n",
    "            df['hw']=df.caught.str.split(\"hit wicket \",expand=True)[1]\n",
    "            hw_id=list(df[\"caught\"].apply(lambda x: x if \"hit wicket \" in x else None).dropna().index)\n",
    "            df[\"caught\"][hw_id]=df[\"caught\"][hw_id].replace(df[\"caught\"][hw_id],'None')\n",
    "        else:\n",
    "            None\n",
    "\n",
    "\n",
    "        ## Substitute Involved\n",
    "\n",
    "        if len(df.caught.str.split(\"sub -\",expand=True).columns)>1:\n",
    "            df['catch_by_substitute']=df.caught.str.split(\"sub -\",expand=True)[1]\n",
    "            sub_id=list(df[\"caught\"].apply(lambda x: x if \"sub -\" in x else None).dropna().index)\n",
    "            df[\"caught\"][sub_id]=df[\"caught\"][sub_id].replace(df[\"caught\"][sub_id],'None')\n",
    "        else:\n",
    "            None\n",
    "\n",
    "\n",
    "        ## lbw \n",
    "\n",
    "        if len(df.CB.str.replace(\"b \",\"\").str.split(\"lbw \",expand=True).columns)>1:\n",
    "                df['lbw_by']=df.CB.str.replace(\"b \",\"\").str.split(\"lbw \",expand=True)[1]\n",
    "                lbw_id=list(df[\"caught\"].apply(lambda x: x if \"lbw\" in x else None).dropna().index)\n",
    "                df[\"bowled\"][lbw_id]=df[\"bowled\"][lbw_id].replace(df[\"bowled\"][lbw_id],'None')\n",
    "                df[\"caught\"][lbw_id]=df[\"caught\"][lbw_id].replace(df[\"caught\"][lbw_id],'None')\n",
    "        else:\n",
    "            None\n",
    "\n",
    "\n",
    "    else:\n",
    "        None\n",
    "\n",
    "\n",
    "    df['match_date']=m.date\n",
    "\n",
    "    df=df.replace(' ', 'None')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Impact for a player in a match is a numerical value which is the sum of his Batting and Bowling Impacts. These Impacts are calculated based on the context of a batting/bowling performance.\n",
    "\n",
    "### Context is based on an intelligent algorithm that quantifies the pressure on the batsman/bowler at every ball of an innings. This is the Pressure Index (PI) value for each ball.\n",
    "\n",
    "### The factors which go into calculating PI include: runs required; overs remaining; quality of batsmen at the crease and those to follow; quality of bowlers and number of overs left for each; pitch/conditions, and how easy/tough it is for batsmen/bowlers.\n",
    "\n",
    "### The PI value is always between O and 1. The closer it is to 1, the higher is the pressure on the batsman. (The converse is true for the bowler.)\n",
    "\n",
    "### The Batting/Bowling Impact is thus a factor not only of the runs scored/wickets taken/economy rate, but also of the pressure under which these performances happened.\n",
    "\n",
    "### While extra credit for match-winning performances are organically built into the algorithm, it is not unusual for a stand-out performance in a losing cause to be the most Impactful in a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_player(index,table):    \n",
    "    tableValues = []\n",
    "    for x in table[index].find_all('tr')[1:]:\n",
    "            td_tags = x.find_all('td')\n",
    "            td_val = [y.text for y in td_tags]\n",
    "            tableValues.append(td_val)\n",
    "\n",
    "\n",
    "    row_headers = []\n",
    "    for x in table[index].find_all('tr'):\n",
    "        for y in x.find_all('th'):\n",
    "            row_headers.append(y.text)\n",
    "    \n",
    "    df=pd.DataFrame(tableValues,columns=row_headers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches(year=str(datetime.today().year)):\n",
    "    \n",
    "    #Get all match_ids with their links using Web scraping method from ESPN website\n",
    "        \n",
    "    url=requests.get(\"https://stats.espncricinfo.com/ci/engine/records/team/match_results.html?class=3;id={};team=6;type=year\".format(year))\n",
    "    soup = bs(url.content,\"html.parser\")\n",
    "    match_links=[]\n",
    "    match_id=[]\n",
    "    for tag in soup.find_all('a',{'href': re.compile(\"/ci/engine/match\"), 'class' : 'data-link'}):\n",
    "           match_links.append(\"https://stats.espncricinfo.com/\"+tag['href'])\n",
    "           match_id.append(re.findall('[0-9]+', tag['href'])[0])\n",
    "    return match_links,match_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_data(match_id):\n",
    "    \n",
    "    #Get Match_details needed for web Url\n",
    "    \n",
    "    m=Match(match_id)\n",
    "    d=pd.DataFrame(m.series)[['match_number','slug','object_id']]\n",
    "    d['match_number'].fillna(\"name\",inplace=True)\n",
    "    series_name=d[d['match_number'].astype(str)==\"name\"].reset_index()['slug'][0]\n",
    "    name=pd.DataFrame(m.team_1)['url_component'].unique()[0]+\"-vs-\"+pd.DataFrame(m.team_2)['url_component'].unique()[0]\n",
    "\n",
    "    #Scraping ESPN\n",
    "    \n",
    "    web = requests.get(\"https://www.espncricinfo.com/series/{}/{}-{}/full-scorecard\".format(series_name,name,match_id))\n",
    "    soup = bs(web.content,\"html.parser\")\n",
    "    table=soup.find_all('table',{'class':'ci-scorecard-table'})\n",
    "    team1_name=str(soup.find_all('span',{'class':'ds-text-tight-l ds-font-bold ds-text-ui-typo hover:ds-text-ui-typo-primary ds-block ds-truncate'})[0]).replace(\">\",\"<\").split(\"<\")[2]\n",
    "    team2_name=str(soup.find_all('span',{'class':'ds-text-tight-l ds-font-bold ds-text-ui-typo hover:ds-text-ui-typo-primary ds-block ds-truncate'})[1]).replace(\">\",\"<\").split(\"<\")[2]\n",
    "    \n",
    "    result=str(soup.find_all('p',{'class':'ds-text-tight-m ds-font-regular ds-truncate ds-text-typo-title'})[0]).replace(\">\",\"<\").split(\"<\")[4]\n",
    "    \n",
    "    # AVoiding No result matches\n",
    "    \n",
    "    if (result!=\"No result\") or (result!=\"Match Abandoned\"):    \n",
    "        df1=scorecard(index=0,table=table,m=m)\n",
    "        df1['team']=team1_name\n",
    "        df1['BATTING']=df1['BATTING'].str.replace(\")\",\"\").str.replace(\"(\",\"-\").str.replace(\"-c\",\"\").replace(regex=True,to_replace=r'[^A-Z a-z .\\-]', value=r'')\n",
    "        df1['recent_no_of_days']=pd.to_datetime(df1['match_date']).apply(lambda x: (date.today()-x.date()).days)\n",
    "\n",
    "        df2=scorecard(index=1,table=table,m=m)\n",
    "        df2['team']=team2_name\n",
    "        df2['BATTING']=df2['BATTING'].str.replace(\")\",\"\").str.replace(\"(\",\"-\").str.replace(\"-c\",\"\").replace(regex=True,to_replace=r'[^A-Z a-z .\\-]', value=r'')\n",
    "        df2['recent_no_of_days']=pd.to_datetime(df2['match_date']).apply(lambda x: (date.today()-x.date()).days)\n",
    "\n",
    "        # Concat both the scorecards\n",
    "\n",
    "        scorecard_all=pd.concat([df1,df2],axis=0).reset_index().drop(['index'],axis=1).replace(np.NaN,\"None\")\n",
    "        scorecard_all['BATTING']=scorecard_all['BATTING'].apply(lambda x:\" \".join(x.split()))\n",
    "        # Players info\n",
    "\n",
    "        ### Team-1\n",
    "\n",
    "        player_info_1=pd.DataFrame(m.team_1_players)[['age_days','age_years','keeper','known_as','player_id','object_id','player_primary_role','popular_name','alpha_name']]\n",
    "        player_info_1['batsmen']=player_info_1['player_primary_role'].apply(lambda x: 0 if 'wicketkeeper' in x else 1 if 'batter' in x else 0)\n",
    "        player_info_1['allrounder']=player_info_1['player_primary_role'].apply(lambda x: 1 if 'allrounder' in x else 0)\n",
    "        player_info_1['bowler']=player_info_1['player_primary_role'].apply(lambda x: 1 if 'bowler' in x else 0)\n",
    "\n",
    "        ### Team-2\n",
    "\n",
    "        player_info_2=pd.DataFrame(m.team_2_players)[['age_days','age_years','keeper','known_as','player_id','object_id','player_primary_role','popular_name','alpha_name']]\n",
    "        player_info_2['batsmen']=player_info_2['player_primary_role'].apply(lambda x: 0 if 'wicketkeeper' in x else 1 if 'batter' in x else 0)\n",
    "        player_info_2['allrounder']=player_info_2['player_primary_role'].apply(lambda x: 1 if 'allrounder' in x else 0)\n",
    "        player_info_2['bowler']=player_info_2['player_primary_role'].apply(lambda x: 1 if 'bowler' in x else 0)\n",
    "\n",
    "        # Concat both the teams player info\n",
    "\n",
    "        players_info=pd.concat([player_info_1,player_info_2],axis=0).reset_index().drop(\"index\",axis=1)\n",
    "        players_info['known_as']=players_info['known_as'].apply(lambda x:\" \".join(x.split()))\n",
    "\n",
    "\n",
    "        #Impact-metric\n",
    "\n",
    "        web = requests.get(\"https://www.espncricinfo.com/series/{}/{}-{}/match-impact-player\".format(series_name,name,match_id))\n",
    "        soup = bs(web.content,\"html.parser\")\n",
    "        table=soup.find_all('table',{'class':'ds-w-full ds-table ds-table-md ds-table-auto'})\n",
    "\n",
    "        if len(table)>0:\n",
    "\n",
    "            impact_df=impact_player(index=0,table=table)\n",
    "\n",
    "            # Merge all the data\n",
    "            data_final=pd.merge(players_info,scorecard_all,how=\"left\",right_on=\"BATTING\",left_on=\"known_as\").merge(impact_df,left_on=\"known_as\",right_on=\"PLAYER\",how=\"left\")\n",
    "            data_final['match_id']=match_id\n",
    "        else:\n",
    "            # Merge all the data\n",
    "            data_final=pd.merge(players_info,scorecard_all,how=\"left\",right_on=\"BATTING\",left_on=\"known_as\")\n",
    "            data_final['match_id']=match_id\n",
    "    else:\n",
    "        scorecard_all=pd.DataFrame()\n",
    "        players_info=pd.DataFrame()\n",
    "        data_final=pd.DataFrame()\n",
    "\n",
    "    \n",
    "    \n",
    "    return scorecard_all,players_info,data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243388\n",
      "1243389\n",
      "1243390\n",
      "1243391\n",
      "1243392\n",
      "1262758\n",
      "1262759\n",
      "1262760\n",
      "1273727\n",
      "1273739\n",
      "1273744\n",
      "1273748\n",
      "1273753\n",
      "1278671\n",
      "1278672\n",
      "1278673\n",
      "1278679\n",
      "1278680\n",
      "1278681\n",
      "1278684\n",
      "1278685\n",
      "1278686\n",
      "1278687\n",
      "1278688\n",
      "1278689\n",
      "1278690\n",
      "1278691\n",
      "1303307\n",
      "1303308\n",
      "1276904\n",
      "1276905\n",
      "1276906\n",
      "1317903\n",
      "1317904\n",
      "1317905\n",
      "1317906\n",
      "1317907\n",
      "1327270\n",
      "1327272\n",
      "1327276\n",
      "1327277\n",
      "1327279\n",
      "1327503\n",
      "1327504\n",
      "1327505\n",
      "1327506\n",
      "1327507\n",
      "1327508\n"
     ]
    }
   ],
   "source": [
    "df_combined=pd.DataFrame()\n",
    "\n",
    "for year in ['2021','2022']:\n",
    "    match_links,match_id=matches(year)\n",
    "    matches_db=pd.DataFrame(list(zip(match_links,match_id)),columns=['match_url','match_id'])\n",
    "    \n",
    "    #Create folder w.r.t year\n",
    "    \n",
    "    path=input()\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        None\n",
    "    else:\n",
    "        os.mkdir(path) \n",
    "    \n",
    "    matches_db.to_csv(path+\"\\matches_db_{}.csv\".format(year))\n",
    "    \n",
    "    for m_id in match_id:\n",
    "        print(m_id)\n",
    "        scorecard_match,players_info,data_final=match_data(m_id)\n",
    "        \n",
    "        scorecard_match.to_csv(path+'\\scorecard_{}.csv'.format(m_id))\n",
    "        players_info.to_csv(path+'\\players_info_{}.csv'.format(m_id))\n",
    "        data_final.to_csv(path+'\\data_final_{}.csv'.format(m_id)) \n",
    "        \n",
    "        #combine all matches data into one csv file\n",
    "        \n",
    "        df_combined=pd.concat([data_final,df_combined],axis=0).reset_index().drop(\"index\",axis=1)\n",
    "        \n",
    "    df_combined.to_csv(path+'\\df_combined_{}.csv'.format(year))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
